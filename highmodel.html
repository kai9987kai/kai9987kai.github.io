<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Actively Improving AI Chatbot â€“ Advanced & Optimized</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- Chart.js for live loss chart -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <style>
    :root {
      --primary-bg: #1a1a1a;
      --secondary-bg: #2d2d2d;
      --accent: #4a90e2;
    }
    html, body {
      margin: 0;
      padding: 0;
      background: var(--primary-bg);
      color: #fff;
      font-family: 'Segoe UI', sans-serif;
      height: 100vh;
      display: flex;
      flex-direction: column;
    }
    /* Chat container */
    #chatContainer {
      flex: 1;
      overflow-y: auto;
      padding: 1rem;
      background: var(--secondary-bg);
      position: relative;
    }
    #chatLog {
      max-height: calc(100% - 2rem);
      overflow-y: auto;
    }
    /* Step bar */
    #stepBar {
      padding: 0.5rem;
      text-align: center;
      background: var(--primary-bg);
      border-top: 1px solid #3d3d3d;
    }
    /* Prompt bar */
    #inputContainer {
      display: flex;
      gap: 0.3rem;
      padding: 0.5rem;
      background: var(--primary-bg);
    }
    #userInput {
      flex: 1;
      padding: 0.4rem;
      font-size: 14px;
      border: 1px solid #3d3d3d;
      border-radius: 4px;
      background: var(--secondary-bg);
      color: #fff;
    }
    #sendButton {
      padding: 0.4rem 0.8rem;
      background: var(--accent);
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 14px;
      transition: opacity 0.2s;
    }
    #sendButton:hover { opacity: 0.9; }
    /* Fixed panels */
    #controls, #infoPanel, #performancePanel {
      position: fixed;
      background: rgba(0,0,0,0.8);
      padding: 0.8rem;
      border-radius: 4px;
      font-size: 14px;
      z-index: 1000;
    }
    #controls {
      top: 1rem;
      right: 1rem;
      width: 280px;
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 0.5rem;
    }
    /* Reset Model button */
    #controls button.resetBtn {
      grid-column: span 2;
      background: #d9534f;
    }
    /* Info panel */
    #infoPanel {
      top: 300px;
      right: 1rem;
      width: 280px;
    }
    #lossChartContainer {
      width: 100%;
      height: 200px;
    }
    /* Performance panel */
    #performancePanel {
      bottom: 1rem;
      right: 1rem;
      width: 280px;
    }
    /* Feedback button style */
    .feedbackBtn {
      background: transparent;
      border: none;
      font-size: 14px;
      cursor: pointer;
      margin-left: 5px;
      color: var(--accent);
    }
  </style>
</head>
<body>
  <div id="chatContainer">
    <div id="chatLog"></div>
    <div id="stepBar">Steps: 0</div>
  </div>
  <div id="inputContainer">
    <input type="text" id="userInput" placeholder="Type your message here..." />
    <button id="sendButton">Send</button>
  </div>
  <div id="controls">
    <div class="grid-col-span-2">
      <label>LR: <input type="number" id="lrInput" value="0.0005" step="0.0001"></label>
      <label>MutRate: <input type="number" id="mutRateInput" value="0.01" step="0.001"></label>
      <label>Decay: <input type="number" id="decayInput" value="0.999" step="0.001"></label>
      <label>Speed: <input type="range" id="speedInput" min="0.5" max="3" step="0.1" value="1"></label>
    </div>
    <button onclick="commander.trainExtra()">Train Extra</button>
    <button onclick="exportModel()">Export Model</button>
    <button onclick="document.getElementById('modelUpload').click()">Import Model</button>
    <button class="resetBtn" onclick="resetModel()">Reset Model</button>
    <input type="file" id="modelUpload" style="display:none" accept=".json,.bin">
  </div>
  <div id="infoPanel">
    <div id="lossChartContainer">
      <canvas id="lossChart"></canvas>
    </div>
  </div>
  <div id="performancePanel"></div>
  
  <script>
    (function(){
      // Set backend to WebGL for GPU acceleration and force lower precision if needed.
      tf.setBackend('webgl');
      tf.env().set('WEBGL_FORCE_F16_TEXTURES', true);

      // Wrap all code in an IIFE.
      
      // Define responses only once.
      const responses = [
        "Here's a joke: ",
        "Here's some advice: ",
        "Here's a quote: ",
        "Did you know? ",
        "I see. Could you tell me more?",
        "That's fascinating!",
        "I'm learningâ€”tell me more.",
        "Let's change the topic. What else is on your mind?",
        "Chuck Norris says: ",
        "Kanye says: "
      ];

      // --- Additional API Functions ---
      async function fetchChuckNorris() {
        try {
          const res = await safeFetch("https://api.chucknorris.io/jokes/random");
          if (res) {
            const data = JSON.parse(res);
            return data.value;
          }
          return "Sorry, no Chuck Norris joke available.";
        } catch (e) {
          console.error("Chuck Norris API error:", e);
          return "Error fetching Chuck Norris joke.";
        }
      }
      async function fetchKanye() {
        try {
          const res = await safeFetch("https://api.kanye.rest");
          if (res) {
            const data = JSON.parse(res);
            return data.quote;
          }
          return "Sorry, no Kanye quote available.";
        } catch (e) {
          console.error("Kanye API error:", e);
          return "Error fetching Kanye quote.";
        }
      }

      // --- Safe Fetch with Fallback ---
      async function safeFetch(url, options = {}) {
        try {
          const response = await fetch(url, options);
          if (!response.ok) throw new Error(`HTTP error! Status: ${response.status}`);
          return await response.text();
        } catch (error) {
          console.error("Fetch error:", error);
          try {
            console.warn("Fallback: attempting fetch with no-cors mode.");
            const fallbackResponse = await fetch(url, { ...options, mode: "no-cors" });
            return await fallbackResponse.text();
          } catch (fallbackError) {
            console.error("Fallback fetch error:", fallbackError);
            return null;
          }
        }
      }

      // --- Public API Functions ---
      async function fetchJoke() {
        const data = await safeFetch("https://icanhazdadjoke.com/", { headers: { "Accept": "text/plain" } });
        return data || "Sorry, no joke available.";
      }
      async function fetchAdvice() {
        const data = await safeFetch("https://api.adviceslip.com/advice");
        try { return data ? JSON.parse(data).slip.advice : "Sorry, no advice available."; }
        catch (e) { return "Sorry, no advice available."; }
      }
      async function fetchQuote() {
        const data = await safeFetch("https://api.quotable.io/random");
        try { return data ? JSON.parse(data).content : "Sorry, no quote available."; }
        catch (e) { return "Sorry, no quote available."; }
      }
      async function fetchCatFact() {
        const data = await safeFetch("https://catfact.ninja/fact");
        try { return data ? JSON.parse(data).fact : "Sorry, no cat fact available."; }
        catch (e) { return "Sorry, no cat fact available."; }
      }
      async function getResponse(action) {
        if (action === 0) {
          const joke = await fetchJoke();
          if (joke && !joke.startsWith("Error")) return responses[0] + joke;
          else return responses[1] + await fetchAdvice();
        } else if (action === 1) {
          const advice = await fetchAdvice();
          if (advice && !advice.startsWith("Error")) return responses[1] + advice;
          else return responses[0] + await fetchJoke();
        } else if (action === 2) {
          const quote = await fetchQuote();
          return "Here's a quote: " + quote;
        } else if (action === 3) {
          const catFact = await fetchCatFact();
          return "Did you know? " + catFact;
        } else if (action === 4) {
          const chuck = await fetchChuckNorris();
          return "Chuck Norris says: " + chuck;
        } else if (action === 5) {
          const kanye = await fetchKanye();
          return "Kanye says: " + kanye;
        } else {
          return responses[action];
        }
      }

      // --- UI Helper Functions ---
      function appendMessage(sender, message, features = null) {
        const msgElem = document.createElement("div");
        msgElem.style.marginBottom = "10px";
        msgElem.innerHTML = `<strong>${sender}:</strong> ${message}`;
        if (sender === "Chatbot" && features) {
          const upBtn = document.createElement("button");
          upBtn.textContent = "ðŸ‘";
          upBtn.classList.add("feedbackBtn");
          upBtn.addEventListener("click", () => recordFeedback(features, true));
          const downBtn = document.createElement("button");
          downBtn.textContent = "ðŸ‘Ž";
          downBtn.classList.add("feedbackBtn");
          downBtn.addEventListener("click", () => recordFeedback(features, false));
          msgElem.appendChild(upBtn);
          msgElem.appendChild(downBtn);
        }
        chatLog.appendChild(msgElem);
        chatLog.scrollTop = chatLog.scrollHeight;
      }
      function argmax(arr) {
        let maxIndex = 0, maxValue = arr[0];
        for (let i = 1; i < arr.length; i++) {
          if (arr[i] > maxValue) { maxValue = arr[i]; maxIndex = i; }
        }
        return maxIndex;
      }
      function calculateReward(message, action) {
        const positiveKeywords = ["joke", "advice", "quote", "cat", "fascinating", "learn"];
        let reward = 0;
        for (let word of positiveKeywords) {
          if (message.toLowerCase().includes(word)) reward += 1;
        }
        if (action >= 2) reward += 0.5;
        return reward;
      }
      function recordFeedback(features, isPositive) {
        const feedbackReward = isPositive ? 5 : -5;
        commander.exp.push({ state: features, action: 0, reward: feedbackReward, nextState: features, done: false });
        logEvent("Feedback recorded: " + (isPositive ? "ðŸ‘" : "ðŸ‘Ž"));
        commander.trainExtra();
      }
      function updateStepDisplay(steps) {
        stepBar.textContent = "Steps: " + steps;
      }
      function updateLossChart(lossData) {
        lossChart.data.labels = lossData.map((v, i) => i);
        lossChart.data.datasets[0].data = lossData;
        lossChart.update();
      }
      function updatePerformancePanel() {
        performancePanel.innerHTML = `Steps: ${commander.stepCount} | Epsilon: ${commander.epsilon.toFixed(3)}`;
      }
      function logEvent(msg) {
        console.log("[CHAT LOG]:", msg);
        let logs = localStorage.getItem("chatLogs");
        logs = logs ? JSON.parse(logs) : [];
        logs.push({ time: new Date().toISOString(), msg });
        localStorage.setItem("chatLogs", JSON.stringify(logs.slice(-100)));
      }

      // --- CommanderAgent Class with Adaptive LR ---
      class CommanderAgent {
        constructor() {
          this.stepCount = 0;
          this.epsilon = 1.0;
          this.exp = [];
          this.learningRate = parseFloat(document.getElementById("lrInput").value);
          this.mutationRate = parseFloat(document.getElementById("mutRateInput").value);
          this.epsilonDecay = parseFloat(document.getElementById("decayInput").value);
          // Model input: 9 features.
          try {
            this.model = this.buildCommanderDQN();
            this.targetModel = this.buildCommanderDQN();
            this.targetModel.setWeights(this.model.getWeights());
          } catch (err) {
            console.error("Model construction error:", err);
            tf.env().set('WEBGL_FORCE_F16_TEXTURES', true);
            this.model = this.buildCommanderDQN();
            this.targetModel = this.buildCommanderDQN();
            this.targetModel.setWeights(this.model.getWeights());
          }
          this.lossHistory = [];
          this.lossData = [];
          this.recentLossAvg = null;
        }
        buildCommanderDQN() {
          const model = tf.sequential();
          // Very large model: hidden layers of 32768, 16384, 8192, 4096, 2048, 1024 units.
          model.add(tf.layers.dense({ units: 22760, inputShape: [9] }));
          model.add(tf.layers.batchNormalization());
          model.add(tf.layers.leakyReLU({ alpha: 0.1 }));
          model.add(tf.layers.dropout({ rate: 0.2 }));
          model.add(tf.layers.dense({ units: 13380 }));
          model.add(tf.layers.batchNormalization());
          model.add(tf.layers.leakyReLU({ alpha: 0.1 }));
          model.add(tf.layers.dropout({ rate: 0.2 }));
          model.add(tf.layers.dense({ units: 8190 }));
          model.add(tf.layers.batchNormalization());
          model.add(tf.layers.leakyReLU({ alpha: 0.1 }));
          model.add(tf.layers.dropout({ rate: 0.2 }));
          model.add(tf.layers.dense({ units: 4090 }));
          model.add(tf.layers.batchNormalization());
          model.add(tf.layers.leakyReLU({ alpha: 0.1 }));
          model.add(tf.layers.dropout({ rate: 0.2 }));
          model.add(tf.layers.dense({ units: 2040 }));
          model.add(tf.layers.batchNormalization());
          model.add(tf.layers.leakyReLU({ alpha: 0.1 }));
          model.add(tf.layers.dense({ units: 1024, activation: 'linear' }));
          model.add(tf.layers.dense({ units: 6, activation: 'linear' }));
          model.compile({ optimizer: tf.train.adam(this.learningRate), loss: 'meanSquaredError' });
          return model;
        }
        extractFeatures(message) {
          const length = message.length;
          const charSum = message.split("").reduce((sum, ch) => sum + ch.charCodeAt(0), 0);
          const avgChar = length > 0 ? charSum / length : 0;
          return [
            length / 100,
            avgChar / 128,
            (message.split(" ").length) / 20,
            Math.random(), Math.random(),
            Math.random(), Math.random(),
            Math.random(), Math.random()
          ];
        }
        decideAction(features) {
          let action;
          if (Math.random() < this.epsilon) {
            action = Math.floor(Math.random() * responses.length);
          } else {
            action = tf.tidy(() => {
              const stT = tf.tensor2d([features]);
              const out = this.model.predict(stT);
              const arr = out.dataSync();
              return argmax(arr);
            });
          }
          return action;
        }
        async step(message) {
          const features = this.extractFeatures(message);
          const action = this.decideAction(features);
          this.exp.push({ state: features, action, reward: calculateReward(message, action), nextState: features, done: false });
          if (this.exp.length > 128) await this.learn();
          if (this.epsilon > 0.05) this.epsilon *= this.epsilonDecay;
          this.stepCount++;
          updateStepDisplay(this.stepCount);
          return { action, features };
        }
        async learn() {
          const batchSize = 64;
          const batch = this.exp.slice(-batchSize);
          const states = batch.map(e => e.state);
          const actions = batch.map(e => e.action);
          const rewards = batch.map(e => e.reward);
          const nextStates = batch.map(e => e.nextState);
          const sT = tf.tensor2d(states);
          const nsT = tf.tensor2d(nextStates);
          const currQ = this.model.predict(sT);
          const nextQ = this.targetModel.predict(nsT);
          const currData = currQ.arraySync();
          const nextData = nextQ.arraySync();
          for (let i = 0; i < batch.length; i++) {
            const maxNext = Math.max(...nextData[i]);
            currData[i][actions[i]] = rewards[i] + 0.99 * maxNext;
          }
          const target = tf.tensor2d(currData);
          try {
            const info = await this.model.fit(sT, target, { epochs: 1, verbose: 0 });
            const loss = info.history.loss[0];
            this.lossHistory.push(loss);
            this.lossData.push(loss);
            // Update moving average of loss.
            const recentLosses = this.lossData.slice(-10);
            this.recentLossAvg = recentLosses.reduce((a, b) => a + b, 0) / recentLosses.length;
            document.getElementById("lossDisplay").textContent = "Loss: " + loss.toFixed(4);
            updateLossChart(this.lossData);
            // Adaptive learning rate: If recent loss is not improving, reduce LR slightly.
            if (this.recentLossAvg && this.recentLossAvg > 0.1) {
              this.learningRate *= 0.98;
            } else {
              this.learningRate *= 1.02;
            }
            this.model.optimizer.learningRate = this.learningRate;
            if (this.stepCount % 100 === 0) {
              const tau = 0.1;
              const weights = this.model.getWeights();
              const targetWeights = this.targetModel.getWeights();
              const updated = weights.map((w, i) => tf.add(tf.mul(w, tau), tf.mul(targetWeights[i], 1 - tau)));
              this.targetModel.setWeights(updated);
              updated.forEach(t => t.dispose());
            }
          } catch (err) {
            console.error("Learning error:", err);
          } finally {
            tf.dispose([sT, nsT, currQ, nextQ, target]);
          }
        }
        trainExtra() {
          for (let i = 0; i < 100; i++) {
            this.step("dummy");
          }
          logEvent("Commander trained extra for 100 steps.");
        }
      }

      // Instantiate the CommanderAgent.
      const commander = new CommanderAgent();

      // Export model function.
      async function exportModel() {
        try {
          await commander.model.save('downloads://chatbot-model');
          logEvent("Model exported successfully.");
        } catch (e) {
          console.error("Export error:", e);
          logEvent("Failed to export model.");
        }
      }

      // Import model functionality.
      document.getElementById("modelUpload").addEventListener("change", async (evt) => {
        const files = evt.target.files;
        if (files.length === 0) return;
        try {
          const loadedModel = await tf.loadLayersModel(tf.io.browserFiles(files));
          commander.model = loadedModel;
          commander.targetModel = loadedModel;
          logEvent("Model imported successfully.");
        } catch (e) {
          console.error("Import error:", e);
          logEvent("Failed to import model.");
        }
      });

      // Reset model: Clear localStorage backups and reload.
      window.resetModel = function() {
        if (confirm("This will reset the model and clear backups. Continue?")) {
          localStorage.removeItem("backup-model");
          localStorage.removeItem("performanceMetrics");
          location.reload();
        }
      };

      // Update loss chart.
      function updateLossChart(lossData) {
        lossChart.data.labels = lossData.map((v, i) => i);
        lossChart.data.datasets[0].data = lossData;
        lossChart.update();
      }

      // Update performance panel.
      function updatePerformancePanel() {
        performancePanel.innerHTML = `Steps: ${commander.stepCount} | Epsilon: ${commander.epsilon.toFixed(3)}`;
      }

      // Handle user message.
      async function handleMessage() {
        const message = userInput.value.trim();
        if (!message) return;
        appendMessage("User", message);
        userInput.value = "";
        const result = await commander.step(message);
        const action = result.action;
        const features = result.features;
        const response = await getResponse(action);
        appendMessage("Chatbot", response, features);
        updatePerformancePanel();
      }

      sendButton.addEventListener("click", handleMessage);
      userInput.addEventListener("keydown", (e) => {
        if (e.key === "Enter") handleMessage();
      });

      // Pre-training routine: 500 samples over 40 epochs.
      async function preTrainChatbot() {
        const inputs = [];
        const labels = [];
        for (let i = 0; i < 500; i++) {
          const text = "sample message " + i;
          const features = commander.extractFeatures(text);
          const action = Math.floor(Math.random() * responses.length);
          const labelVec = Array(responses.length).fill(0);
          labelVec[action] = 1;
          inputs.push(features);
          labels.push(labelVec);
        }
        const xs = tf.tensor2d(inputs);
        const ys = tf.tensor2d(labels);
        try {
          await commander.model.fit(xs, ys, { epochs: 40 });
          logEvent("Pre-training complete.");
        } catch (err) {
          console.error("Pre-training error:", err);
          logEvent("Pre-training encountered an error.");
        } finally {
          xs.dispose();
          ys.dispose();
        }
      }
      preTrainChatbot();

      // Background training: every 30 seconds run extra training.
      setInterval(() => {
        // Randomize delay slightly (Â±20%) to avoid synchronized spikes.
        const delay = 30000 * (0.8 + Math.random() * 0.4);
        setTimeout(() => {
          commander.trainExtra();
          updatePerformancePanel();
        }, delay);
      }, 30000);

      // Every 20 seconds, fetch random data from additional APIs.
      setInterval(async () => {
        const quote = await fetchQuote();
        if (quote && !quote.startsWith("Error")) {
          commander.step(quote);
          logEvent("Background training with quote: " + quote.slice(0, 50) + "...");
        }
        const catFact = await fetchCatFact();
        if (catFact && !catFact.startsWith("Error")) {
          commander.step(catFact);
          logEvent("Background training with cat fact: " + catFact.slice(0, 50) + "...");
        }
        const chuck = await fetchChuckNorris();
        if (chuck && !chuck.startsWith("Error")) {
          commander.step(chuck);
          logEvent("Background training with Chuck Norris: " + chuck.slice(0, 50) + "...");
        }
        const kanye = await fetchKanye();
        if (kanye && !kanye.startsWith("Error")) {
          commander.step(kanye);
          logEvent("Background training with Kanye: " + kanye.slice(0, 50) + "...");
        }
      }, 20000);

      updatePerformancePanel();

      // Auto-backup: every 60 seconds save model and performance metrics to localStorage.
      setInterval(async () => {
        try {
          await commander.model.save('localstorage://backup-model');
          const metrics = {
            stepCount: commander.stepCount,
            epsilon: commander.epsilon,
            lossData: commander.lossData.slice(-20)
          };
          localStorage.setItem("performanceMetrics", JSON.stringify(metrics));
          logEvent("Model and metrics auto-backup saved to localStorage.");
        } catch (e) {
          console.error("Auto-backup error:", e);
        }
      }, 60000);

      // On startup, try to load backup from localStorage.
      (async function loadBackup() {
        try {
          const backupModel = await tf.loadLayersModel('localstorage://backup-model');
          commander.model = backupModel;
          commander.targetModel = backupModel;
          const metrics = localStorage.getItem("performanceMetrics");
          if (metrics) {
            const parsed = JSON.parse(metrics);
            logEvent("Backup metrics loaded: " + JSON.stringify(parsed));
          }
          logEvent("Backup model loaded from localStorage.");
        } catch (e) {
          console.log("No backup model found, starting fresh.");
        }
      })();

      updatePerformancePanel();

    })();
  </script>
</body>
</html>
